NLP assignment 1:

As first part, experiment with the options of the vectorizer to improve the classification using logistic regression. You are required to look at the documentation of the functions. You can also add other pre-processing step to the text if you feel like it.



1) Between the problem as regression and the problem as multi-class classification, 
the priority is the problem as regression.
Indeed, the classification perspective does penalize each error in the same way, while the regression perspective considers the difference between the predicted value and the real value (prediction 8 for real value 2 is way worse than prediction 3 for value 2). The classification perspective is a tool to understand the problem better and experiment.


2) In the multi-class classification, 
the most important measures are F1s (especially macro and micro), 
since it is a complex measure that considers more aspects than the simple accuracy.

3) You are free to use any pre-processing technique you want, you are not bounded to use TfidfVectorizer

4) It is not unusual to not reach a "satisfying" score, especially in the first step: our code makes use of a pretty simple classifier. 
Our purpose is to show you both the impact of the pre-processing and the choice of the classifier.

5) There are no threshold values that you have to reach with the measurements to obtain a certain score. 
The score will be assigned based on the correctness of the methodology and the extent to which different solutions have been explored and discussed.

6) In each code section, you have to deliver a single approach, but if you have observations or interesting alternative approaches, you can mention them in the .txt file


regression is better than classification because the label order is meaningful... sartori

consider F1-score as more meaningful

any preprocessing other than vectorizer

purpose is to show the impact of pre-processing then classifier
correctness of the methodology and the extent to which different solutions have been explored and discussed.

what .txt file? can I write them in markdown?



Anyway:

shpw the impact of pre-processing:
which techniques?
parameters of tfidvect:

min_df e max_df, binary, stop_words, N-grams, fitting on train_test intersection is overfitting on test? lexicon vocabulary approaches, 

inquiry f1 score, not accuracy!


a. min_df, max_df composition is linear?
b. various tokenizations

intanto sto vectorizer cosa da fuori???
per ogni recensione fa il conto delle parole che ci sono e? 0.294234567, 0.??
 
(recensione, parola)	Tf-idf-weighted document-term matrix

(0, 59148)		0.23132510204077741
(0, 50646)		0.13870298022191505
(0, 4465)		0.044752214927255805

importance to f1-score, what is it?
f1 = 2 PR / P+R
Precision = pos / classificati pos (tp + fp) = quanto peschi con precisione i pos
Recall = pos/ all pos (tè + fn) = quanti pos riesci a pescare

binary aiuta un po'
la lemmatization di nltk aiuta un po'
un po' di cutoff delle parole più frequenti e meno frequenti aiuta
aumentare gli n_grams non aiuta




overfitting on test!


gridsearch with  10 stratified folds on the training set returns default min,max df values.
also binarization is not preferred.
A great imporvement is instead given by nltk tokenization, and a greater one by


PART 2
how to evaluate a classifier against another?
same stratified kfoldsplit?





HOW IS iT OVERFITTING SO MUCH?
0.88 with cv on train gives 0.45 acc on test, how can this be?
something is informative for the train set only, it must be infrequent n-grams, no?
TROPPE FEATURES

not an n-folds issue: 0.1 to 0.5 gives same 0.44 val score... but
0.1 gives 0.48 acc?

last but not least: timing considerations


cv 0.1 on mlp improves 0.42 0.31mmm è più la random run

less features or deeper network!

miglior regressorcv con nltk.word_tokenize, solo monogrammi 

0.43 -> 0.45: monogrammi o neuroni?



which solutions we have explored:

vectorizer min_df max_df



le feature sono davverom olte in confronto ai


PART 1


Features are way more than the available examples:
monograms are 78k vs 25k examples,
bigrams are way way more, following the binomial coefficient law.

In order to decrease the strain on the classifier we inquiry on ways to reduce the number of less relevant ones.

TFiDF vectorizer provides several parameters for this purpose:
- max_df specifies the max frequency of allowed n-grams, thus allowing remotion of very frequent, non informative ones.

- min_df specifies the min frequency, used to remove the low-frequency words tail

- max_features 

- binarization of count

Preprocessing fatto:

- nltk.word_tokenize
- w w/o stemming
- naive negation

(mostrare l'effetto dei diversi algoritmi sulla stessa frase train[0])

timing: poche features -> fast



PART 2

classifiers:
MLPC is a fast classifier that provides early stopping

overfitting due to features/samples imbalance seems the limit of bag of words method.





Any preprocessing we want:

Normalization: US==USA != us

Lemmatization: am are is -> be
Stemming, simpler

chap3
evaluation of language models

trough application: extrinsic
trogh perplexity: intrinsic, held out





~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
part 1
# part 1: 
# extrinsic evaluation:
# study of text preprocessing techniques by their effect on the classification task
# with a baseline logistic regression classifier


# Text normalization with regex and nltk tokenization, 
# Lemmatization by stemming with Porter algorithm,
# and naive negation handling with NOT_word replacement


### toikenization with pattern is greatly faster and nltk.word_tokenize does not improve significantly
### stemming with porterstemmer significantly improves f1-scores and accuracy
### pystemmer for speed


####after logreg classification

# interpretability of LR
# result analysis with sentiment words plots ecc

# then 2/3 classifiers compared on f1 and speed:
# LR, NB binaryzation, NLP


# hyperparameter search is done with cross validation with 10 folds
# this allows to not optimize on the available test set

# processing speed of tokenization is an issue with nltk

# interpretability of the logistic regression?!?

# other classifiers: Naive Bayes generative model and vectorizer count binarization
# speed vs accuracy

# overfitting in cross validation and regularization 


# fix 1/10 2/10


part 2
# LR
# The invaluable advantage of logistic regression classifier is in it's interpretability

# NB
# naive bayes does worst with too much features
# binarization impact is risible, contrary to what the theory suggests

# MLP
# early stopping is needed because overfitting is present
# going deeper with the model has no impact, this is probably due to the
# "flattened" bag-of-words representation of text, that removes any structure in the data



tfidf real meaning
could do better with countvectorizer?
what are we really cutting with 0.98 0.004?

cluster documents






